{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "co9OYJ8ru28m"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Implementation From Scratch**"
      ],
      "metadata": {
        "id": "mD0JfR9tuVt9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class activation_functions:\n",
        "\n",
        "  @staticmethod\n",
        "  def step(x : int):\n",
        "    return 0 if x < 0 else 1\n",
        "\n",
        "  @staticmethod\n",
        "  def sigmoid(x : int):\n",
        "    return 1 / (1 + np.e ** -x)\n",
        "\n",
        "  @staticmethod\n",
        "  def tanh(z : int):\n",
        "    return (np.e ** z - np.e ** -z) / (np.e ** z + np.e ** -z)\n",
        "\n",
        "  @staticmethod\n",
        "  def relu(x : int):\n",
        "    return max(0, x)\n",
        "\n",
        "  @staticmethod\n",
        "  def leaky_relu(x : int):\n",
        "    return max(0.01 * x, x)\n",
        "\n",
        "  @staticmethod\n",
        "  def softmax(z : np.array):\n",
        "    z = np.array(z)\n",
        "    return np.divide(np.e ** z, np.sum(np.e ** z))"
      ],
      "metadata": {
        "id": "_8kcfM6-u7aD"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class loss_functions:\n",
        "\n",
        "  @staticmethod\n",
        "  def MAE(y_pred : np.array, y_true : np.array):\n",
        "    return np.abs(np.mean(np.subtract(y_true, y_pred)))\n",
        "\n",
        "  @staticmethod\n",
        "  def MSE(y_pred : np.array, y_true : np.array):\n",
        "    return np.abs(np.mean(np.subtract(y_true, y_pred) ** 2))\n",
        "\n",
        "  @staticmethod\n",
        "  def CrossEntropyLoss(y_pred : np.array, y_true : np.array):\n",
        "    y_pred = activation_functions.softmax(y_pred)\n",
        "    loss = 0\n",
        "    for i in range(len(y_true)):\n",
        "      loss += -1 * y_true[i] * np.log(y_pred[i])\n",
        "    return loss"
      ],
      "metadata": {
        "id": "W1bGkYqg4Idr"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array(\n",
        "    [\n",
        "        [1.2, 0.7],\n",
        "        [0.3, 0.5],\n",
        "        [1.0, 1.5]\n",
        "    ]\n",
        ")\n",
        "\n",
        "y = np.array(\n",
        "    [0, 1, 0]\n",
        ")"
      ],
      "metadata": {
        "id": "c13lOA5n7VEL"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(71)"
      ],
      "metadata": {
        "id": "dDJe3M87Hxzl"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SLP: # Single Layer Perceptron (A Neuron)\n",
        "\n",
        "  def gradient_descent(self, x : np.array, y : np.array, epochs : int, lr : float, print_after_epoch : int):\n",
        "    num_features = x.shape[1]\n",
        "    weights = np.array(np.random.randn(num_features))\n",
        "    bias = np.random.randn()\n",
        "    n = len(x)\n",
        "\n",
        "    grad_weights = np.zeros(num_features)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "      y_pred = activation_functions.sigmoid(np.dot(x, weights) + bias)\n",
        "\n",
        "      loss = loss_functions.MSE(y_pred, y)\n",
        "\n",
        "      grad_weights = (1 / n) * np.dot(np.transpose(x), np.subtract(y_pred, y))\n",
        "      grad_bias = np.mean(np.subtract(y_pred, y))\n",
        "\n",
        "      weights -= np.dot(lr, grad_weights)\n",
        "      bias -= lr * grad_bias\n",
        "\n",
        "      if (epoch + 1) % print_after_epoch == 0:\n",
        "        print(f\"Epoch : {epoch + 1} | Loss : {loss} | Weights : {weights} | Bias : {bias}\")\n",
        "\n",
        "    return weights, bias\n",
        "\n",
        "  def fit(self, x : np.array, y : np.array, epochs : int, lr : float, print_after_epoch : int):\n",
        "    self.weights, self.bias = self.gradient_descent(x, y, epochs, lr, print_after_epoch)\n",
        "\n",
        "  def predict(self, x : np.array):\n",
        "    return activation_functions.sigmoid(np.dot(x, self.weights) + self.bias)"
      ],
      "metadata": {
        "id": "5u4mzcz6F4_p"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Model = SLP()\n",
        "Model.fit(x, y, 10000, 0.01, 1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dObgcSs5OFKP",
        "outputId": "e748c244-75d5-475d-ec19-3e96eb91d0cf"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 1000 | Loss : 0.12184642328645436 | Weights : [-0.96272761 -1.14227645] | Bias : 0.6428471501332358\n",
            "Epoch : 2000 | Loss : 0.08290881740586105 | Weights : [-1.59956365 -1.29490762] | Bias : 1.3081630365594756\n",
            "Epoch : 3000 | Loss : 0.05788362758537375 | Weights : [-2.13953251 -1.42944392] | Bias : 1.8481250782700485\n",
            "Epoch : 4000 | Loss : 0.04167792754677702 | Weights : [-2.59859797 -1.54478543] | Bias : 2.2979188951390204\n",
            "Epoch : 5000 | Loss : 0.030953710804792308 | Weights : [-2.99385699 -1.6444761 ] | Bias : 2.679675867837722\n",
            "Epoch : 6000 | Loss : 0.02364916009057605 | Weights : [-3.33865582 -1.73159783] | Bias : 3.009187185150956\n",
            "Epoch : 7000 | Loss : 0.018523985806067775 | Weights : [-3.64309873 -1.80858333] | Bias : 3.2977997327909483\n",
            "Epoch : 8000 | Loss : 0.014826246836547414 | Weights : [-3.9148219  -1.87731191] | Bias : 3.5537833020187692\n",
            "Epoch : 9000 | Loss : 0.012090142996969172 | Weights : [-4.1596449  -1.93923395] | Bias : 3.7832749739850575\n",
            "Epoch : 10000 | Loss : 0.010019491535420302 | Weights : [-4.3820582  -1.99547711] | Bias : 3.9909153332208835\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "round(Model.predict([1.2, 0.7]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovbikDJCTI0o",
        "outputId": "ef164944-5cce-4edd-fd0f-74b94d82c16b"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Implementation Using PyTorch**"
      ],
      "metadata": {
        "id": "wXkMibp2uOSr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "t7Fs-9hlUGAA"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Model = nn.Sequential(\n",
        "  nn.Linear(2, 1, bias = True),\n",
        "  nn.Sigmoid()\n",
        ")"
      ],
      "metadata": {
        "id": "FS-0pYsEUM7U"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(Model.parameters(), lr = 0.01)\n",
        "loss_func = nn.MSELoss()"
      ],
      "metadata": {
        "id": "REtnrm2wVJv4"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10000\n",
        "\n",
        "for _ in range(epochs):\n",
        "  y_pred = Model(torch.FloatTensor(x))\n",
        "  loss = loss_func(y_pred, torch.FloatTensor(y))\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKl1Nk-0Wtro",
        "outputId": "06ac97c6-bcc4-4e3d-d78d-d5384d496c06"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([3])) that is different to the input size (torch.Size([3, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_state_dict = Model.state_dict()"
      ],
      "metadata": {
        "id": "Yi-gZQCWXgZS"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights = model_state_dict['0.weight'].numpy()\n",
        "bias = model_state_dict['0.bias'].numpy()\n",
        "\n",
        "print(\"Weights:\", weights)\n",
        "print(\"Bias:\", bias)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KN-obg5dXozb",
        "outputId": "c28091aa-4e55-4a07-fd13-23ad46d07f71"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights: [[-0.00042698 -0.00040582]]\n",
            "Bias: [-0.6935576]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  print(round(float(Model(torch.FloatTensor([1.2, 0.7])))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xoyLxBtX73-",
        "outputId": "c04d4319-e07e-4626-b4c3-c947e1a56006"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    }
  ]
}